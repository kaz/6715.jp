{"pageProps":{"tag":"インフラ","entries":[{"type":"article","slug":"30","body":"NaruseJunチームでISUCON11予選に出ました。\n\n- チームメンバー[^team]\n\t- [@to_hutohu](https://twitter.com/to_hutohu)\n\t- [@takashi_trap](https://twitter.com/takashi_trap)\n\t- [@sekai67](https://twitter.com/sekai67)\n- 結果\n\t- スコア: [919720](https://isucon.net/archives/56021246.html)\n\t- 本戦に行ける！🎉🎉\n\t\t- ココ最近のNaruseJunチームは追試失敗率が高く[^fail]て、2年間本戦に行けていませんでした。悲願達成感があります。\n\n[^team]: 全員が今年出題の[東京工業大学デジタル創作同好会traP](https://trap.jp/)のOBです。\n[^fail]: 運営サイドにも[定評のある](https://twitter.com/sora_h/status/1429334456616189957)失敗率。\n\n## やったこと\n\n- NaruseJunチームは基本的に個々人が勝手に改善を突っ込んていくスタイル\n\t- 担当範囲などはあえて決めておらず、全員アプリを触るしインフラもいじる\n\t- ミドルウェアの設定、アプリコード、デプロイスクリプトが全部入った[リポジトリ](https://github.com/narusejun/isucon11-qualify)を使った\n\t\t- それぞれローカルで作業、ブランチを切ってリモートにプッシュ、サーバ上でプルしてデプロイ、といった動き\n\t\t\t- ローカルではテストしない（環境まわりでハマるのは時間の無駄なので）\n\t\t\t- 3人で別々に動いているので、声掛けでサーバの占有権を取ってベンチを投げ、それで動作確認する感じ\n- 初動だけは担当作業を決めていた\n\t- to_hutohu: マニュアル読み込み\n\t- takashi_trap: リポジトリ、デプロイスクリプト周りの準備\n\t- sekai67: 環境立ち上げ、計測ツール類準備\n\t\t- 細かいツールの導入などはすべてansibleで行う\n\t\t\t- [最初の変更](https://github.com/narusejun/isucon11-qualify/commit/6b74fb20740ca5fa31070d7763437d3867e6f063)をリポジトリに入れてデプロイするまで **17分**\n\t\t\t\t- 最初の動きをよく詰めておいたので、スムーズに改善へ移れた\n- 計測結果を元に改善ポイントを見つけた\n\t- **「推測するな、計測せよ」**\n\t- pprof, [fgprof](https://github.com/felixge/fgprof), [alp](https://github.com/tkuchiki/alp), [pt-query-digest](https://www.percona.com/doc/percona-toolkit/LATEST/pt-query-digest.html), [netdata](https://github.com/netdata/netdata) を見ていた\n\t\t- pprofは基本的にFlame Graphだけ見れば大体わかる\n\t- [pprotein](https://github.com/kaz/pprotein)というツールを作って、使った\n\t\t- pprof, alp, pt-query-digestのデータをサーバから収集し、Webブラウザ上で表示できるようにしたもの\n\t\t\t- 過去の計測結果を見れたり、チーム内で計測結果を見ながら相談できたりするので便利\n\t\t- こういうツールを作るのが最近流行ってそう\n\t\t\t- https://twitter.com/_tsuzu_/status/1429064558203731973\n\t\t\t- https://diary.hatenablog.jp/entry/2021/08/22/175403\n\t\t- pproteinはいまのところオープンソースなので、ご活用ください\n\t\t\t- ただしREADMEは書いてない\n- 以下2点の理由から、15時過ぎから新たな改善を入れるのをほぼストップし、追試対策など安全に通過するための戦略に切り替えた（前年の反省）\n\t- 80万点に到達した15時時点で、次点は10万点代、大多数が10万点未達という状況であったこと\n\t- 特定の状況下（http2のGOAWAYハンドリングミス[^goaway]）でベンチマーカーがエラーになり、場合によってはスコアなしになる可能性が残っていたこと\n\t\t- 競技中、これがこちら側のミスであるか、運営側のミスであるかを判断できなかった[^clar]ため、念の為修正を行う判断に至ったが、結果としては不要だった\n\n[^goaway]: 詳細については[予選結果](https://isucon.net/archives/56021237.html)の「不具合について」を参照。\n[^clar]: 競技中に質問を行い「ベンチマーカーのバグである」との回答を頂いてはいましたが、チーム内での議論の結果、必ずしもそうとは言えないのではないかという結論になりました。\n\n### こぼれ話\n\n- 14:30〜15:10まで、コミットするたびに点数が指数関数的に増加した\n\t- あまりにも上がるし、自分たちの想像以上に上がるので、けっこう驚いていた\n\t\t- 運営さんもかなり驚いたたようで、「ベンチマーカーの実装がバグっている可能性がある」として個別で改善方法を確認されました\n\t\t\t- 結果としてバグではなかったのでハッピーエンド\n\t\t- 点数が上がるたびにバグの疑念が強まり、[ベンチマーカー実装担当](https://twitter.com/ryoha000/status/1429097219391574024)の顔がどんどん曇っていったらしい\n\n![](score.png)\n\n### 具体的な改善内容\n\n- だいたい時系列順\n- 初期スコア: 2000くらい\n\t- 改善後スコアは必ずしも当該の改善のみが寄与しているわけではないので注意\n\n#### `isu_condition` テーブルにインデックスを貼る\n\n- 時間: 10:40\n- スコア: 19000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/4132537145c01a54b86207c9e130d3d94b8dc895\n- 根拠\n\t- pt-query-digest結果から。この時点での合計クエリ時間上位2つがこれだった\n\t```\n\tselect * from `isu_condition` where `jia_isu_uuid` = ? order by `timestamp` desc limit ?\n\tselect * from `isu_condition` where `jia_isu_uuid` = ? order by timestamp desc\n\t```\n\n#### `/api/trend` で返すデータを 0.5 秒ごとに作るようにする\n\n- 時間: 11:10\n- スコア: 26000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/1e24895db95c0ce776b8751bcf90a49e37ea17b0\n- 根拠:\n\t- pprofのFlame Graphから。getTrendで発行してるSELECTに時間がかかっている[^pprof]。\n\n[![](fg1.png)](fg1.png)\n\n[^pprof]: 次項のFlame Graphと見比べるとgetTrendがすっかり見えなくなっていることがわかります。\n\n#### `isu_condition` テーブルを水平分割 + ログを出さない\n\n- 時間: 12:20\n- スコア: 42000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/fda74ca7e56b70a58a7a49c773cb892d3dae6765\n\t\t- UUIDを使って振り分け先のサーバを決定して、そのサーバから読み書きする。\n\t\t- トランザクションが邪魔なので、消す。よく読むと、トランザクションなしでも正常に処理できることが分かる。\n- 根拠\n\t- alpから。POST `^/api/condition/.+$`の合計時間が大きい。GETもそこそこ大きい。\n\t- pprofのFlame Graphから。getIsuConditions/postIsuConditionsが重い。\n\n[![](fg1.png)](fg1.png)\n\n#### iconをDBにつっこむのをやめてファイルに書き出す\n\n- 時間: 12:50\n- スコア: 52000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/e3cc31346fb89455a0f0123e9ea08156914e28c4\n\n#### 微調整\n\n- 時間: 13:30\n- スコア: 64000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/68f2d06510e6ad147a623bce64dcc0d2b1ab56ca\n\t\t- あえてtrendを返すのを遅くして、ユーザー数の増加を抑える。\n\t- https://github.com/narusejun/isucon11-qualify/commit/72368dc1582670ccdce6fc2e727bb82da5292b30\n\t\t- DBを3台から2台に減らして、appへよりCPU時間を配分する。\n- 根拠\n\t- netdata等から。appとDBが同居しているサーバでCPU使用率がほぼ100%なのに対して、DBのみが動くサーバではまだ余裕があったため。\n\n#### backendを複数台に\n\n- 時間: 14:00\n- スコア: 72000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/99ec56508bb5fc501133f06cc913e20c98de1ec7\n\t\t- appを3台にして、postIsuConditionのみを複数台で処理させる。\n- 根拠\n\t- netdata等から。appサーバからDBを剥がしてもまだCPU使用率が100%だったため。\n\n#### getIsuConditionsFromDBの高速化\n\n- 時間: 14:30\n- スコア: 107000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/7981a778309e216b3734d817c3458c15f20d5564\n\t\t- Generated Column追加、SQLでLIMITする。\n- 根拠\n\t- pt-query-digestから。以下のクエリが遅い＋Rows_sentが異常に大きい。\n\t  ```\n\t  select * from `isu_condition` where `jia_isu_uuid` = ? and `timestamp` < ? order by `timestamp` desc\n\t  ```\n\t- pprofのFlame Graphから。getIsuConditionsFromDBの圧倒的存在感。。。\n\n[![](fg3.png)](fg3.png)\n\n#### `postIsuCondition` バルクインサート + postIsuCondition全受理\n\n- 時間: 14:40\n- スコア: 158000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/d375e46e3d72547b8a3d67a97f26133981264680\n\t- https://github.com/narusejun/isucon11-qualify/commit/4e2da32e02b079fbe56ed2188dabd5639ef7f2c3\n\n#### nginx調整\n\n- 時間: 14:50\n- スコア: 295000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/9e47a40a1f1af444a07fa93c1cc3a33372904b5a\n\t\t- getIsuGraphを3台処理に変更、nginx-backend間通信のkeepalive化。\n- 根拠\n\t- netdata等から。1台目のappサーバがキツそうだったのと、その割にほか2つがヒマそうだったので。\n\n#### getTrend調整\n\n- 時間: 15:00\n- スコア: 346000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/6cc6d718095b0e1d4ffbc3277e53d8ac4966bf52\n\t\t- 意図的にtrendを返すのを遅くしていたところを少しだけ早くしてユーザー数を増やす。\n\n#### グラフ作成時の取得データ量を減らす\n\n- 時間: 15:00\n- スコア: 631000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/659cb46e1210c56aaabf6f40681bfe705453a686\n\t\t- WHERE句にtimestampの範囲で絞る条件を追加。\n- 根拠\n\t- pt-query-digestから。以下のクエリが遅い＋Rows_sentが異常に大きい。\n\t```\n\tselect * from `isu_condition` where `jia_isu_uuid` = ? order by `timestamp`\n\t```\n\n#### nginx調整\n\n- 時間: 15:10\n- スコア: 836000〜932000くらい\n- コミット\n\t- https://github.com/narusejun/isucon11-qualify/commit/3d9f96bfe12f263a0ea8f3aa759b8e73c2659f0a\n\t\t- nginxとappが同居してる場合はnginx-app間通信をunix domain socket経由に\n\t- https://github.com/narusejun/isucon11-qualify/commit/5f4f37918c900ae106da1b54da66d59399da3a41\n\t\t- nginx-app間のkeepaliveコネクション数調整\n\n#### 微調整\n\n- 時間: 16:00〜17:00\n- スコア: 1010000〜1173984(ベストスコア)\n- パラメータをいろいろ調整してた\n\t- MySQL設定\n\t- nginx設定\n\t- getTrend待ち時間\n\n#### 最終\n\n- 時間: 17:00〜\n- スコア: 988417(最終スコア)\n- http2のGOAWAY問題[^goaway]でベンチマークがまれに失敗する問題の対応\n\t- 安全に追試をパスできるように少し性能を落とした\n\n## おわり\n\n運営の皆さんありがとうございました。\n","title":"ISUCON11予選に参加した","image":null,"tags":["ISUCON","インフラ","参加記"],"date":"2021-08-23T00:00:00.000Z","updated":"2021-08-22T19:00:52.000Z"},{"type":"article","slug":"29","body":"おうちネット、最近は楽天ひかりを契約してます。\n楽天モバイルとセットで申し込むと、ひかりも通信料1年間無料になって激アツです。\n\n[IQ1 Advent Calendar 2020](https://adventar.org/calendars/5197) - 16日目の記事です。\n\n[IQ1 Advent Calendar 2020](https://adventar.org/calendars/5197)\n\n## 自宅サーバ\n\n世はまさに大クラウド時代！\n**自宅サーバ**とかいう文字列を目にすることも、こころなしか少なくなったような気がします。\n\n普通の家庭向けインターネット接続サービスではIPv4アドレスが1つしか割当されないのに対して、宅内にはたくさんの端末がある……ので、NAPTでうまいことさばいているのが普通かと思います。\nこういう環境下で家にサーバを置くには、いわゆるポート開放[^1]、静的NAPTの設定が必要になるわけですね。\n\n[^1]: この言い方は好きじゃないですが、よく使われているのでコレで……\n\n## IPv4 over IPv6での自宅サーバ公開\n\n楽天ひかりはIPv4 over IPv6に対応しています。\nこのやりかたでIPv4ネットワークに接続すると、旧来のPPPoEによる接続と比較してパフォーマンスが良い、とされています。\n\nIPv4 over IPv6の実現する方式にはいくつか種類があって、楽天ひかりはXpass（クロスパス）と呼ばれる方式を利用しているとのこと。なんだかカッコいい名前がついていますが、一般的にはDS-Liteと呼ばれるやつですね。\n\nが、DS-Lite方式のIPv4 over IPv6では、いわゆるポート開放ができません。残念。\nでは自宅サーバは公開できないのか？というとそうでもなくて、依然として旧来のPPPoE接続はできるので、こっちを通るようにすれば良いです。\n\n## DS-LiteとPPPoEの併用\n\n家庭用のルータだとそもそもコレができる機種は限られています。\nここは課金ポイントです。業務用っぽいやつを買いましょう。\n\nボクはYAMAHAのNVR510を買いました。\n具体的な設定手順は省きますが、DS-LiteとPPPoEの両方でIPv4ネットワークに接続できたとしましょう。\n\n![](1.png)\n\n当然ですが、DS-Lite側とPPPoE側で別々のアドレス`X.X.X.X`と`Y.Y.Y.Y`を持っているような状態になっています。\n\n普段の通信は、パフォーマンスが良いとされているDS-Lite側(`tunnel 1`)を通したいです。\nなので、デフォルトゲートウェイはこっち側にします。\n\n```\nip route default gateway tunnel 1\n```\n\nこういう感じになっています。\n\n![](2.png)\n\n## 自宅サーバ宛の通信をPPPoE側で受け入れる\n\n今回はHTTPサーバを公開するということにして、PPPoE側のアドレスに来た`80/tcp`の通信をサーバが受け取れるように、静的NAPT[^2]エントリを追加します。\n\n[^2]: YAMAHA製品ではIPマスカレードという名称\n\n```\nnat descriptor type 1 masquerade\nnat descriptor masquerade static 1 100080 192.168.0.250 tcp www\npp select 1\n  ip pp nat descriptor 1\n```\n\nこれで、外の端末からの通信がサーバに到達できるようになりました。\nTCPだと、まず`SYN`パケットが送られてきますよね。\n\n![](3.png)\n\nで、サーバは`SYN/ACK`で応答するわけです。3-wayハンドシェイクというやつの2番目です。\nクライアント(`Z.Z.Z.Z`)がどこにいるなんて末端のサーバは知りません。なので、とりあえず家庭内のルータに丸投げします。当の家庭内ルータもその上位ルータへ投げるだけです。このとき、**デフォルトゲートウェイをDS-Lite側に設定**しているので、当然この`SYN/ACK`もそっち側に行ってしまいます。\n\n![](4.png)\n\nすると、クライアントからするとおかしな事が起こっているように見えるわけです。`Y.Y.Y.Y`に送った`SYN`の返答がなぜか`X.X.X.X`から帰ってくる……これではTCP接続は確立できません。\n返りの通信もPPPoEを通るようにしないとダメそう。\n\nちなみに、UDPならこの状態でも通信できる可能性があります。\n\n## 返りの通信もPPPoEを通す\n\nポリシーベースルーティング（PBR）[^3]をします。\nある条件に合致するような通信だけ、別の経路に流したりできる機能です。\nこれも業務用クラスのルーターじゃないと使えない場合が多そうです。\n\n[^3]: YAMAHA製品ではフィルタ型ルーティングに相当\n\n今回は、HTTPサーバを公開したいという状況なので、送信元が件の自宅サーバでかつポート番号が`80`のときだけ、PPPoE側(`pp 1`)にルーティングするようにします。\n\n```\nip filter 100080 pass 192.168.0.250 * tcp www *\nip route default gateway pp 1 filter 100080 gateway tunnel 1\n```\n\nこれで、こうなります。`SYN`のdstと`SYN/ACK`のsrcが一致して、クライアントは`ACK`を返してくれることでしょう……晴れて接続確立です。\n\n![](5.png)\n\n## おしまい\n\nおわりです。\nなんかもっといい方法ないのかな。\n\n### おまけ：パケットキャプチャ\n\nサーバ側はこう。`192.168.0.250`が宅内のサーバで、`133.130.113.115`は外にいるクライアント。\n`SYN/ACK`をめちゃ再送している。\nクライアントが再送した`SYN`もいっぱい来てる。\n\n![](server.png)\n\nクライアント側。\n`SYN`を再送してる。サーバが送った`SYN/ACK`はそもそも届いてない。\n途中の誰かが捨ててるのかな……（ここわからん）\n\n![](client.png)\n","title":"DS-Lite/PPPoE併用環境で自宅サーバの通信だけPPPoEを通す","image":null,"tags":["DS-Lite","PPPoE","アドベントカレンダー","インフラ","ネットワーク"],"date":"2020-12-16T00:00:00.000Z","updated":"2021-01-07T09:09:45.000Z"},{"type":"article","slug":"28","body":"ISUCON10お疲れさまでした。運営の皆さん、ありがとうございました。\n\nボク、[@sekai67](https://twitter.com/sekai67)はNaruseJunチームの一員として出場しました。結果はこう。\n\n- 予選では、本選出場圏内の点数を取って余裕をカマしていましたが、追試をパスできずに予選落ち。\n- 本選では、[本選ライブ](http://isucon.net/archives/55063136.html)の企画で、並行チームとして問題に取り組ませてもらう。\n\t- 競技中最高得点 **52567** を記録するものの、追試をパスできず記録なし。伝統芸能\n\nこれは記念写真です。\n\n![](score.png)\n\nまあ追試で落ちてるんですけどね！\n\n参加記はチームメイトの[@to_hutohu](https://twitter.com/to_hutohu)と[@takashi_trap](https://twitter.com/takashi_trap)が書いてくれると信じて、ボクはちょっとしたこぼれ話を書いていきます。\n\n## やらかしリスト\n\n予選、本選どちらにおいても、思い返すとまあいろいろやらかしたんですが、今回は興味深かった2つを抜粋して掘り下げます。\n\n- 予選時、再起動試験を5回ぐらいして、追試落ちは絶対ない状態まで持っていったのに無事追試落ちした話\n- 本選開始後、初手でサーバの1台を使い物にならなくしてチームメイトを困惑させた話\n\n## 予選の追試で落ちた\n\n### 経緯\n\n予選では、チームメイトの2人がわりとギリギリまでアプリ実装のバグ取りを詰めていたので、ボクが1人で再起動試験や後片付けを担当することになりました。\n去年も再起動後に正しく動作させることができずに予選落ちしていますので、今年こそは！と念入りに何度も行っていました。\n\n5回ほど再起動してもOK、再起動後にもデータも正しく引き継がれている。絶対落ちないだろコレは！！！\nと自信満々で競技を終えたわけですが、結果発表でチーム名が呼ばれることはありませんでした……\n\n夜中、凹みつつも競技で使ったサーバの様子を見に行ってみると……\nDBサーバが落ちてるやんけ！！！！！なんで？？！？！？？！？？！！！\n\n### 理由\n\napparmorのポリシー(mysql-serverパッケージに入ってる`/etc/apparmor.d/usr.sbin.mysqld`)が生きていて、systemdがmariadbの起動を検知できておらず、`systemctl stop`相当の処理がかかったため。\n\nUbuntuで、最初にmysqlが動いている状態から、これをmariadbに置き換えると起動しなくなるという事例があります。\nこちらの記事が詳しいです。\n\n[Ubuntuでmysql-serverをmariadb-serverで置き換えるとsystemd経由でmariadbが起動できない](/posts/24/)\n\n## 疑問1: mariadbに入れ替えたときにto-hutohuが`aa-remove-unknown`でポリシーを消したのでは？\n\n先ほど紹介した記事を書いたのはボクです。ですので、もちろんこの挙動については知っていました。\n上記記事で紹介されている対策法をもちろん講じています。\n\nが、これはそもそも恒久対応ではありませんでした……！\nわかりにくい書き方でゴメンナサイ。\n\n先の記事で言及している、\n\n> /etc/apparmor.d/usr.sbin.mysqldは空のファイルで上書きされますが、AppArmorがすでに読み込んでいるプロファイルは削除されません。\n> また、systemctl reload apparmorしても、OSを再起動しても、一度読み込まれたプロファイルが勝手に削除されることはありません。\n\nここの理解が曖昧、あるいは間違っています。\n\nポリシーがOSを再起動しても消えない原因は、apparmorのポリシーキャッシュのせいで、`/etc/apparmor.d/cache/usr.sbin.mysqld`が存在して、かつ`/etc/apparmor.d/usr.sbin.mysqld`よりタイムスタンプが新しい場合、キャッシュのほうが読み込まれるという挙動をします。\n\n- `/etc/apparmor.d/cache/usr.sbin.mysqld`が作成されるのは、mysql-serverインストール時。\n\t- つまりタイムスタンプは → `Sep 11 11:34`\n- `/etc/apparmor.d/usr.sbin.mysqld`のタイムスタンプは、mariadbパッケージが作成された時。\n\t- つまりタイムスタンプは → `Jul 20 10:50`\n\nですので、`/etc/apparmor.d/usr.sbin.mysqld`が更新されたにも関わらず、キャッシュのほうがずっと読み込まれ続けてしまうのでした……！\n\n正しい対応は、`systemctl reload apparmor`でした。\nこれでキャッシュのflushが走り、正しくmariadbに起動するようになります。\n\n例の記事については、そのうち書き換えておきますね……\n\n### 疑問2: sekaiが再起動試験を行ったときにうまく動作していたのは何故？\n\n再起動後15分以内にのみ試験していたからです。\n\nAppArmorのせいでmariadbに起動に失敗するというのは、厳密に言うと、 **mariadbは起動に成功しているんだけどsystemdがそれを検知できていない** ということ。\nsystemdは一定時間（デフォルトで15分）以内にサービスの起動を確認できないと、ご丁寧にExecStopを走らせてくれるのです……！\n\nsekaiが再起動したのは **11:39:26 UTC** ごろ。\n\n```\n-- Reboot --\nSep 12 11:39:26 s2 systemd[1]: Starting MariaDB 10.1.44 database server...\nSep 12 11:39:32 s2 mysqld[1244]: 2020-09-12 11:39:32 139768179551360 [Note] /usr/sbin/mysqld (mysqld 10.1.44-MariaDB-0ubuntu0.18.04.1) starting as process 1244 ...\nSep 12 11:45:11 s2 systemd[1]: Stopped MariaDB 10.1.44 database server.\n-- Reboot --\n```\n\n11:45:11にStopしてるのは、このあともう一度再起動試験したためです。\n\nこの付近のkern.logは以下。\n\n```\nSep 12 11:39:35 s2 kernel: [   42.180656] audit: type=1400 audit(1599910775.956:18): apparmor=\"DENIED\" operation=\"sendmsg\" info=\"Failed name lookup - disconnected path\" error=-13 profile=\"/usr/sbin/mysqld\" name=\"run/systemd/notify\" pid=1244 comm=\"mysqld\" requested_mask=\"w\" denied_mask=\"w\" fsuid=111 ouid=0\n```\n\nsd-notify失敗してるので、この時点でもAppArmorのポリシーが生きています。\nsystemdはこのときずっとmariadbが上がってくるのを待っている状態です。\nただし、mariadb自体は起動しているので、アプリへのリクエストは通る状態です。\n（sekaiのこの状態でずっと再起動試験をしていたわけです。バカですねえ。）\n\n一方で、運営による再起動が行われたと思われる時刻(14:20:38 UTC つまり 23:20:38 JST)付近のログは以下のとおり。\n\n```\n-- Reboot --\nSep 12 14:20:38 s2 systemd[1]: Starting MariaDB 10.1.44 database server...\nSep 12 14:20:42 s2 mysqld[1100]: 2020-09-12 14:20:42 140238334753920 [Note] /usr/sbin/mysqld (mysqld 10.1.44-MariaDB-0ubuntu0.18.04.1) starting as process 1100 ...\nSep 12 14:35:41 s2 systemd[1]: mariadb.service: Start operation timed out. Terminating.\nSep 12 14:35:43 s2 systemd[1]: mariadb.service: Failed with result 'timeout'.\nSep 12 14:35:43 s2 systemd[1]: Failed to start MariaDB 10.1.44 database server.\n```\n\n15分立ったのでmariadbがshutdownされたと思われます。\n以下は`/var/lib/mysql/error.log`です。\n\n```\n2020-09-12 14:35:41 140238333712128 [Note] /usr/sbin/mysqld: Normal shutdown\n2020-09-12 14:35:41 140238333712128 [Note] Event Scheduler: Purging the queue. 0 events\n2020-09-12 14:35:41 140236692629248 [Note] InnoDB: FTS optimize thread exiting.\n2020-09-12 14:35:41 140238333712128 [Note] InnoDB: Starting shutdown...\n2020-09-12 14:35:41 140238333712128 [Note] InnoDB: Waiting for page_cleaner to finish flushing of buffer pool\n2020-09-12 14:35:43 140238333712128 [Note] InnoDB: Shutdown completed; log sequence number 3710056674\n2020-09-12 14:35:43 140238333712128 [Note] /usr/sbin/mysqld: Shutdown complete\n```\n\n実際にアプリにリクエストが来たのは、15:03:13 UTCでした。\n\n```\nSep 12 14:20:45 s1 isuumo[903]: ⇨ http server started on [::]:1323\nSep 12 15:03:13 s1 isuumo[903]: [mysql] 2020/09/12 15:03:13 packets.go:122: closing bad idle connection: unexpected read from socke\nSep 12 15:03:13 s1 isuumo[903]: [mysql] 2020/09/12 15:03:13 connection.go:158: driver: bad connection\nSep 12 15:03:13 s1 isuumo[903]: [mysql] 2020/09/12 15:03:13 packets.go:122: closing bad idle connection: unexpected read from socke\nSep 12 15:03:13 s1 isuumo[903]: [mysql] 2020/09/12 15:03:13 connection.go:158: driver: bad connection\n```\n\nこのとき、もうmariadbはshutdown済みなので、当然アプリは動かないわけですね……\n\n## 開始後即サーバを破壊\n\n### 経緯\n\n本選始まって直後の話。\n\nNaruseJunチームでは、Makefileをタスクランナー的に使っていて、[ここ](https://github.com/narusejun/isucon10-final/blob/master/Makefile)にデプロイコマンドを書いていました。\nsekaiがアプリにpprofを埋め込んだコードをプッシュし、サーバ上にデプロイしようとして`make deploy`を叩いたところ、なぜか途中で`sh: Command not found`のエラーが出てmakeが終了しました。\n\nアレ？`sh`って存在しないんだっけと思い、今度は`ls -l /usr/bin/sh`を実行してみると、今度は`bash: /usr/bin/ls: No such file or directory`が……\nここで全てを悟ります。これ、シェル組み込みのコマンド以外、全て使えなくなってるな……？\n\n心当たりがないわけではありませんでした。3人共、ある会話が頭をよぎりました……\nあれは予選時のことです――――\n\n> sekai「ミドルウェアの設定ファイルなども、リポジトリに含めてしまって、デプロイ時にrsyncで配置するようにしませんか？」\\\n> takashi「rsyncですか？どうやってやるんですか」\\\n> sekai「コマンド一発でできますよ。[こう](https://github.com/narusejun/isucon10-qualify/blob/master/Makefile#L50)ですね」\n\n```\n$ ls files\netc/       home/      lib/\n$ sudo rsync -r files/ /\n```\n\n> takashi「**これってもともとサーバ上にあるファイルが消えたりしませんか？**」←ここフラグ\\\n> sekai「大丈夫ですよ。ほら、追加したファイルだけ更新されてるでしょ？」\n\n予選では確かに、このコマンドでうまくデプロイできていました。\nですので、本選でも同じように設定ファイル類を配置しようとしていました。\n\nしかしながら、事実、サーバが壊れました。何故でしょう……\nこのときのログはこうでした。\n\n```\n〜〜〜略〜〜〜\nmake[1]: Leaving directory '/home/isucon/isucon10-final/app/webapp/golang'\nsudo rsync -v -r s1/ /\nsending incremental file list\ndeploy.sh\nskipping non-regular file \"etc/mysql/my.cnf\"\netc/envoy/config.yaml\netc/mysql/debian-start\netc/mysql/debian.cnf\netc/mysql/my.cnf.fallback\netc/mysql/mysql.cnf\netc/mysql/conf.d/mysql.cnf\netc/mysql/conf.d/mysqldump.cnf\netc/mysql/mysql.conf.d/mysql.cnf\netc/mysql/mysql.conf.d/mysqld.cnf\netc/systemd/system/envoy.service\netc/systemd/system/xsuportal-api-golang.service\netc/systemd/system/xsuportal-web-golang.service\nhome/isucon/env\nlib/\nlib/systemd/\nlib/systemd/system/\nlib/systemd/system/mysql.servicesent 11,952 bytes  received 375 bytes  24,654.00 bytes/sec\ntotal size is 10,449  speedup is 0.85\nsh s1/deploy.sh\nmake: sh: Command not found\nmake: *** [Makefile:54: start] Error 127\n```\n\nう〜ん、`--delete`オプションも付けてないし、このログを見ても特におかしくないしなあ。\n本選時はそう思っていました。\n\nここを詳しく調査する時間がもったいないので、運営にサーバをリセットしてもらい（ご迷惑おかけしました……）、とりあえず危険なMakefileは使用禁止として競技に戻りました。\n\n### その後\n\n競技は無事(?)終了し、翌日。ちゃんと調査しました。\n\nさて、件のログをよ〜く見ると、なんだかヤバそうなところが見つかりますね！？\n\n正解は`lib/`とだけ書いてある行です。\nこれは、rsyncによって`lib/`というディレクトリ、今回は宛先が`/`なので、要は`/lib`が作成されたという意味です。\nんん？？それはマズくないか？？？？？\n\nマズいです。コマンドがほぼ使えなくなったのは、間違いなく`/lib`にある共有ライブラリなどが消滅したからでしょう。\n\nでも、予選時はちゃんと動いていたんです。じゃあなんで？？？\n\n答えは、Ubuntuのバージョン違いにありました。\n予選では18.04、本選では20.04です。各バージョンでのルートディレクトリがどうなっているかと言うと……\n\n18.04では、こう。\n\n```\n# ls -l /\ntotal 64\ndrwxr-xr-x   2 root root 4096 Sep 21 17:17 bin\ndrwxr-xr-x   2 root root 4096 Apr 24  2018 boot\ndrwxr-xr-x   5 root root  360 Oct  4 07:46 dev\ndrwxr-xr-x   1 root root 4096 Oct  4 07:46 etc\ndrwxr-xr-x   2 root root 4096 Apr 24  2018 home\ndrwxr-xr-x   8 root root 4096 May 23  2017 lib\ndrwxr-xr-x   2 root root 4096 Sep 21 17:16 lib64\ndrwxr-xr-x   2 root root 4096 Sep 21 17:14 media\ndrwxr-xr-x   2 root root 4096 Sep 21 17:14 mnt\ndrwxr-xr-x   2 root root 4096 Sep 21 17:14 opt\ndr-xr-xr-x 174 root root    0 Oct  4 07:46 proc\ndrwx------   2 root root 4096 Sep 21 17:17 root\ndrwxr-xr-x   1 root root 4096 Sep 25 22:33 run\ndrwxr-xr-x   1 root root 4096 Sep 25 22:33 sbin\ndrwxr-xr-x   2 root root 4096 Sep 21 17:14 srv\ndr-xr-xr-x  13 root root    0 Oct  4 07:46 sys\ndrwxrwxrwt   2 root root 4096 Sep 21 17:17 tmp\ndrwxr-xr-x   1 root root 4096 Sep 21 17:14 usr\ndrwxr-xr-x   1 root root 4096 Sep 21 17:17 var\n```\n\n一方で20.04では……？\n\n```\n# ls -l /\ntotal 48\nlrwxrwxrwx   1 root root    7 Sep 25 01:20 bin -> usr/bin\ndrwxr-xr-x   2 root root 4096 Apr 15 11:09 boot\ndrwxr-xr-x   5 root root  360 Oct  4 07:46 dev\ndrwxr-xr-x   1 root root 4096 Oct  4 07:46 etc\ndrwxr-xr-x   2 root root 4096 Apr 15 11:09 home\nlrwxrwxrwx   1 root root    7 Sep 25 01:20 lib -> usr/lib\nlrwxrwxrwx   1 root root    9 Sep 25 01:20 lib32 -> usr/lib32\nlrwxrwxrwx   1 root root    9 Sep 25 01:20 lib64 -> usr/lib64\nlrwxrwxrwx   1 root root   10 Sep 25 01:20 libx32 -> usr/libx32\ndrwxr-xr-x   2 root root 4096 Sep 25 01:20 media\ndrwxr-xr-x   2 root root 4096 Sep 25 01:20 mnt\ndrwxr-xr-x   2 root root 4096 Sep 25 01:20 opt\ndr-xr-xr-x 171 root root    0 Oct  4 07:46 proc\ndrwx------   2 root root 4096 Sep 25 01:23 root\ndrwxr-xr-x   1 root root 4096 Sep 25 22:34 run\nlrwxrwxrwx   1 root root    8 Sep 25 01:20 sbin -> usr/sbin\ndrwxr-xr-x   2 root root 4096 Sep 25 01:20 srv\ndr-xr-xr-x  13 root root    0 Oct  4 07:46 sys\ndrwxrwxrwt   2 root root 4096 Sep 25 01:23 tmp\ndrwxr-xr-x   1 root root 4096 Sep 25 01:20 usr\ndrwxr-xr-x   1 root root 4096 Sep 25 01:23 var\n```\n\nアッ……（完全に理解）\n\nUbuntu 20.04では、`/lib`は通常のディレクトリではなく、`/usr/lib`へのシンボリックリンクでした！\nrsyncでは、デフォルトではシンボリックリンクの先がディレクトリであっても、それを辿ってその先にコピーをしたりしません。\nソース側のディレクトリでそのまま上書きして、もとのリンクは消してしまうんですね……！\n\n### 教訓\n\nこの悲劇を回避するには、rsyncの`--keep-dirlinks`というオプションを使うべきでした。\n以下、`man rsync`より引用です。\n\n> -K, --keep-dirlinks\n>     This option causes the receiving side to treat a symlink to a directory as though it were a real directory, but only if it matches a real directory from the sender. Without this option, the receiver's symlink would be deleted and replaced with a real directory.\n>     For example, suppose you transfer a directory lqfoorq that contains a file lqfilerq, but lqfoorq is a symlink to directory lqbarrq on the receiver. Without --keep-dirlinks, the receiver deletes symlink lqfoorq, recreates it as a directory, and receives the file into the new directory. With --keep-dirlinks, the receiver keeps the symlink and lqfilerq ends up in lqbarrq.\n\nちょうどボクが踏んだ罠について言及されています。\nrsyncは気をつけて使います……\n\n## おしまい\n\nISUCONは学びが多い。\n\nあと、予選で雑にmysqlの全テーブルをMEMORYストレージエンジンにしたらメモリが完売してSSHできなくなって焦るなどの事件もありました。\n（運営に再起動してもらって事なきを得ました。）\n","title":"ISUCON10 やらかしリスト","image":null,"tags":["AppArmor","ISUCON","systemd","インフラ","参加記"],"date":"2020-10-04T00:00:00.000Z","updated":"2021-01-07T13:52:12.000Z"},{"type":"external","url":"https://engineering.mercari.com/blog/entry/phisical-server-setup/","publisher":"メルカリエンジニアリング","title":"物理サーバのセットアップをon-the-fly ISO patchingで自動化した話","tags":["mercari","自動化","インフラ"],"date":"2020-08-28T00:00:00.000Z"},{"type":"external","url":"https://qiita.com/sekai/items/b5e5e05da2dfe6ff1bf3","publisher":"Qiita","title":"Name Service SwitchでConoHaインスタンスのIPアドレスを引く","tags":["Qiita","アドベントカレンダー","ConoHa","NSS","インフラ"],"date":"2019-12-19T22:00:46.000Z"},{"type":"article","slug":"24","body":"Ubuntu(18.04 LTS)でmysql-serverをmariadb-serverで置き換えるとsystemd経由でmariadbが起動できない。\n\n## 追記\n\nこの記事には一部誤りがあります。\n以下の記事も合わせてご覧ください。\n\n[/posts/28/](/posts/28/)\n\n# トラブル\n\nタイトルの通りです。\nUbuntu 18.04で発生したトラブルですが、他のバージョンでも起こり得そうな予感がします。おそらく。\n\n```bash\n$ sudo apt install mysql-server\n$ sudo apt purge mysql-server\n$ sudo apt install mariadb-server\n```\n\nとすると、最後の`apt install`が妙に遅い事に気が付きます。\nコレは、aptがインストール後におせっかいでmariadbを起動してくれるのですが、何らかの原因でしばらく経ってもmariadbが起動しないためです。\n\nその後、`systemctl start mariadb`を試しても、しばらくした後に起動失敗します。\n\n```bash\n$ sudo systemctl start mariadb\nJob for mariadb.service failed because a timeout was exceeded.\nSee \"systemctl status mariadb.service\" and \"journalctl -xe\" for details.\n```\n\n## 調査\n\n### systemdのログ\n\n```bash\n$ sudo systemctl status mariadb\n● mariadb.service - MariaDB database server\n   Loaded: loaded (/lib/systemd/system/mariadb.service; enabled; vendor preset: enabled)\n   Active: failed (Result: timeout) since Tue 2018-07-10 01:20:10 JST; 36s ago\n Main PID: 2404 (code=exited, status=0/SUCCESS)\n\nJul 10 01:18:38 localhost systemd[1]: Starting MariaDB database server...\nJul 10 01:18:38 localhost mysqld[2404]: 2018-07-10  1:18:38 139689982721152 [Note] /usr/sbin/mysqld (mysqld 10.1.29-MariaDB-6) starting as process 2404 ...\nJul 10 01:20:08 localhost systemd[1]: mariadb.service: Start operation timed out. Terminating.\nJul 10 01:20:10 localhost systemd[1]: mariadb.service: Failed with result 'timeout'.\nJul 10 01:20:10 localhost systemd[1]: Failed to start MariaDB database server.\n```\n\n**timeout**しているようです。\nしかしながら、`mysqld[2404]: ...`から始まる行を見ると、どうやら起動できているようにも見えますが……？\n\n### 接続してみる\n\n`systemctl start mariadb`を実行後、シェルが待機中に別のシェルからMariaDBに接続してみると、普通に接続できます。\n\n```bash\n$ mysql -u root\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MariaDB connection id is 2\nServer version: 10.1.29-MariaDB-6 Ubuntu 18.04\n\nCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMariaDB [(none)]>\n```\n\nやはり、DBサーバーの起動自体はできているようですが、`systemd`が起動に成功したことを検知できていないようです。\n\n### systemd unit定義の確認\n\nsystemdでプロセスを起動するための設定ファイルを確認してみます。\n`/lib/systemd/system/mariadb.service`にあります。\n\n注目すべきは、以下の設定です。\n```\n[Service]\nType=notify\n```\n\nこれは、[sd_notify](https://www.freedesktop.org/software/systemd/man/sd_notify.html)を使ってプロセスの起動完了をsystemdへ通知する設定であることを表しています。\nmariadbは起動できているのに、systemdがそれを認識していない、ということはどうやらこの`sd_notify`が正しく送信されていないのではないか？と疑われます。\n\n### auditログ\n\n`sd_notify`はUNIXドメインソケット(`/run/systemd/notify`)を介してsystemdに通知を送信しますが、パーミッションも特に問題なく、アクセスできそうですが……？\n次に疑うのはSELinuxやAppArmorといった強制アクセス制御機能です。UbuntuはデフォルトでAppArmorが有効なので、怪しいです。\n\nauditログを確認します\n\n```bash\n$ journalctl -n 1 _TRANSPORT=audit\nJul 10 01:42:59 localhost audit[3057]: AVC apparmor=\"DENIED\" operation=\"sendmsg\" info=\"Failed name lookup - disconnected path\" error=-13 profile=\"/usr/sbin/mysqld\" name=\"run/systemd/notify\" pid=3057 comm=\"mysqld\" requested_mask=\"w\" denied_mask=\"w\" fsuid=112 ouid=0\n```\n\nAppArmorによって、`sd_notify`の送信が拒否されているのが発見できました。\nようやく尻尾を掴みましたね……\n\n## 原因\n\n`mysql-server`をインストールすると、AppArmorプロファイルが同時にインストールされ、有効化されます。\nこのプロファイルは`/etc/apparmor.d/usr.sbin.mysqld`に設置されます。\n\nhttps://www.apt-browse.org/browse/ubuntu/xenial/main/amd64/mysql-server-5.7/5.7.11-0ubuntu6/file/etc/apparmor.d/usr.sbin.mysqld\n\nこのプロファイルでは、限られたディレクトリへのアクセスのみを許可しており、`sd_notify`で使うソケットへはアクセスできません。\nしかしながら、`mysql-server`では、プロセス起動検知に`Type=simple`を使用しているため、これは問題になりません。\n\n`mysql-server`をアンインストールし、`mariadb-server`をインストールすると、`/etc/apparmor.d/usr.sbin.mysqld`は空のファイルで上書きされますが、AppArmorがすでに読み込んでいるプロファイルは削除されません。\nまた、`systemctl reload apparmor`しても、OSを再起動しても、一度読み込まれたプロファイルが勝手に削除されることはありません。\n\n……なので、プロセス起動検知に`Type=notify`を使う`mariadb-server`にもこのプロファイルが適用されてしまい、`sd_notify`が失敗してsystemdがタイムアウトする、というオチでした。\n\n## 解決法\n\nUbuntuでは、削除されたプロファイルをアンロードするコマンド`aa-remove-unknown`が用意されています。\n`mariadb-server`をインストールした後、これを実行すれば良いです。\n\n```bash\n$ sudo aa-remove-unknown\nRemoving '/usr/sbin/mysqld'\n```\n\nコレで正常に起動できるようになります。\n\n```bash\n$ sudo systemctl start mariadb\n$ sudo systemctl status mariadb\n● mariadb.service - MariaDB database server\n   Loaded: loaded (/lib/systemd/system/mariadb.service; enabled; vendor preset: enabled)\n   Active: active (running) since Tue 2018-07-10 01:55:56 JST; 15s ago\n Main PID: 4753 (mysqld)\n   Status: \"Taking your SQL requests now...\"\n    Tasks: 27 (limit: 1112)\n   CGroup: /system.slice/mariadb.service\n           └─4753 /usr/sbin/mysqld\n```\n\n# おしまい\n\n[traP](https://trap.jp)で[部内ISUCON](https://twitter.com/to_hutohu/status/1014097600209825792)をしていて、とりあえずmysqlを入れている人が多かったので、なんとなく**「mariadbに替えた方がいいよ！」**と言ったら起動できなくなる人が続出して阿鼻叫喚でした。\n\n[ICTSC](https://icttoracon.net)みたいですね。\n\nおわり。\n","title":"Ubuntuでmysql-serverをmariadb-serverで置き換えるとsystemd経由でmariadbが起動できない","image":null,"tags":["インフラ","Ubuntu","Linux","MySQL","MariaDB","systemd"],"date":"2018-07-10T00:00:00.000Z","updated":"2021-01-07T09:09:45.000Z"},{"type":"external","url":"https://trap.jp/post/306/","publisher":"東京工業大学デジタル創作同好会traP","title":"ICTトラブルシューティングコンテスト #ICTSC9 に参加した話","tags":["traP","ICTSC","インフラ","参加記"],"date":"2018-04-01T00:00:00.000Z"},{"type":"external","url":"https://trap.jp/post/334/","publisher":"東京工業大学デジタル創作同好会traP","title":"PrometheusでConoHa APIからメトリクスを取得してみる","tags":["traP","アドベントカレンダー","インフラ","ConoHa","監視","Prometheus"],"date":"2017-12-24T00:00:00.000Z"},{"type":"article","slug":"21","body":"備忘録！\n\n# 全自動HTTPS\n\n[Let's Encrypt](https://letsencrypt.org/)の登場でHTTPSがぐっと身近になりましたが、やっぱり証明書をホスト名毎に取得するのは結構面倒ですし、90日毎に更新しなきゃいけないのも大変です。\n\nhttps://letsencrypt.org/\n\nそこで、[OpenResty](https://openresty.org/en/)(nginxにいろいろ足したやつ)に[lua-nginx-auto-ssl](https://github.com/GUI/lua-resty-auto-ssl)を入れて、全自動で証明書取得から更新までしてくれる環境を作りたいと思います。\n例によってArchLinuxでやります。\n\n## インストール\n\nOpenRestyを入れます。\nAURからPKGBUILDを落としてきてmakepkgでパッケージを作ってインストールします。\n```sh\ngit clone https://aur.archlinux.org/openresty.git\nmakepkg --syncdeps --install --skippgpcheck\n```\n\nlua-nginx-auto-sslのインストールにLuaRocksを使うので、同様にインストール。\n```sh\ngit clone https://aur.archlinux.org/openresty_luarocks.git\nmakepkg --syncdeps --install\n```\n\nLuaRocksでlua-nginx-auto-sslを入れる。\n```sh\n/opt/openresty/luajit/bin/luarocks install lua-resty-auto-ssl\n```\n\n## 設定\n\nArch公式リポジトリのnginxと同じ感じの操作感にするために、いろいろシンボリックリンクを貼ります。\n```sh\nln -s /opt/openresty/nginx/conf /etc/nginx\nln -s /opt/openresty/nginx/logs /var/log/nginx\nln -s /opt/openresty/bin/openresty /usr/bin/nginx\nln -s /usr/lib/systemd/system/openresty.service /usr/lib/systemd/system/nginx.service\n```\n\nlua-nginx-auto-sslで取得する証明書の鍵アルゴリズムとか、取得失敗時に使う自己署名証明書とかを用意。\n```sh\nmkdir -p /etc/nginx/ssl/letsencrypt/conf.d\nprintf 'KEY_ALGO=\"prime256v1\"\\nCONTACT_EMAIL=\"example@narusejun.com\"' > /etc/nginx/ssl/letsencrypt/conf.d/custom.sh\nopenssl req -new -newkey rsa:2048 -days 3650 -nodes -x509 -keyout /etc/nginx/ssl/fallback_key.pem -out /etc/nginx/ssl/fallback_crt.pem -subj \"/CN=NaruseJun/\"\nchown -R http:http /etc/nginx/ssl\n```\n\n`/etc/nginx/ssl`は、lua-nginx-auto-sslが証明書を置いたりするのに使うディレクトリです。\n後ほど、nginxの設定でこのディレクトリを指定します。\n\nOpenRestyの実行ユーザ（Archのデフォルトは`http`）がこのディレクトリに書き込み出来ないと証明書の取得に失敗するので、chmodしています。\n\n### OpenSSL 1.0系を使う設定\n\nlua-nginx-auto-sslが内部て使っているletsencryptクライアントの**dehydrated**はバージョンが少々古くて、OpenSSL 1.1系に対応していません。\nArchLinuxはOpenSSL 1.1系なので、このまま運用すると**証明書が取得できているのにdehydratedが落ちて**しまいます。\nlua-nginx-auto-sslくんはアクセスが有るたびに証明書を取得しようとするので、あっという間にRateLimitに引っかかってしまいます……！\n\nということで、OpenSSL 1.0系を使ってくれるようにdehydratedをパッチします。\n\n```sh\npacman -Sy openssl-1.0\nsed -i \"2a shopt -s expand_aliases\\nalias openssl=openssl-1.0\\n\" /opt/openresty/luajit/bin/resty-auto-ssl/dehydrated\n```\n\n### nginxの設定\n\nlua-nginx-auto-ssl特有の設定をいろいろ入れないといけません。\n\n[lua-nginx-auto-ssl](https://github.com/GUI/lua-resty-auto-ssl)のドキュメントを読めば大体わかりますが、\nハマる可能性のあるポイントをいかにリストアップしておきます。\n\n- resolverを必ず設定する\n- ホスト毎に必ず`location /.well-known/acme-challenge/`の設定を入れる\n- `auto_ssl:set(\"allow_domain\", ...)`を必ず設定する\n\n全部設定したのがコレです。\n\nhttps://github.com/kaz/openresty-autossl-sample-setting\n\n## 動かす\n\n```sh\nsystemctl start nginx\nsystemctl enable nginx\n```\n\n初回アクセス時は、証明書の取得が完了するまでレスポンスが返ってこないので、ちょっと時間がかかります。\n途中で作った自己署名証明書が使われてしまう場合は、証明書の取得に失敗しています。\n`/var/log/nginx/error.log`にエラーメッセージが出力されているので、確認しましょう。\n\n# おわり\n\nこれで放っといても勝手に証明書を更新してくれたり、nginxの設定をコピーすれば新しいホストに対して証明書を発行してくれる環境ができました！\nlua-nginx-auto-sslを導入したので、このブログもSSL化してみました。\n\n## 余談\n\nLet's Encryptでワイルドカード証明書が発行できるようになるそうです。すごい。\n\nhttps://twitter.com/letsencrypt/status/882985570401701888\n\n## 追記\n\nワイルドカード証明書が発行できるようになりました。\n\n[ワイルドカード証明書](/posts/23/)\n","title":"lua-nginx-auto-sslで全自動HTTPS","image":null,"tags":["インフラ","自動化","SSL","nginx","lua","OpenResty"],"date":"2017-07-08T00:00:00.000Z","updated":"2021-01-08T10:53:56.000Z"},{"type":"article","slug":"20","body":"HLSを使ったライブストリーミングを試してみます\n\n[前々回](/posts/18/)・[前回](/posts/19/)の続きです。\n\n<!--more-->\n\n# あらすじ\n\n前々回はPythonからWin32APIをバシバシ叩いてきりたん好きなコトを喋らせることができるようになったのでした。\n\n[クラウド東北きりたん その1 ～Win32APIでVOICEROIDを操作～](/posts/18/)\n\n前回はAzureのWindowsServerにHTTPリクエストを送ってきりたん好きなコトを喋らせるサーバができたのでした。\n\n[クラウド東北きりたん その2 ～AzureのWindowsServerでVOICEROIDを動かす～](/posts/19/)\n\n今回は、**HTTP Live Streaming**(HLS)を用いてきりたんボイスをライブ配信してみようと思います！\n\n![](kiritan.png)\n\n# HTTP Live Streaming\n\n**HTTP Live Streaming**とは、Appleが開発したHTTPベースのストリーミング配信プロトコルです。\n静的な動画ファイルのストリーミング配信はもちろん、ライブ配信(生放送)もできたり、\nアダプティブストリーミングと呼ばれる回線速度に応じて配信するビットレートを変更する技術も利用可能です。\n\n最近話題の[AbemaTV](https://abema.tv/)なんかでも、HLSで配信を行っています。\nちなみに、Twitterにアップされた動画もHLSで配信されています。\n\nストリーミング配信プロトコルと聞くと、複雑そうな気がしてきますが、HLSはHTTPベースで非常に単純です。\nザックリと説明を書いてみます。\n\n## HLSのしくみ\n\nHLSでの配信は、`.ts`ファイルと`.m3u8`ファイルによって行われます。\n\n### ts\n\n`.ts`ファイルは、**MPEG-2 TS**と呼ばれる形式で、配信される映像・音声そのものが格納されます。\n\n配信されるデータは一定の秒数ごとに分割し、このMPEG-2 TS形式で保存しておきます。\n分割された`.ts`ファイルは、HTTPでダウンロードできるようにしておきます。\n\nちなみに、日本のデジタルテレビ放送もこのMPEG-2 TSで配信されています。\n\n### m3u8\n\n`.m3u8`ファイルは、配信ファイルのインデックスです。\n先述した`.ts`に分割された映像・音声データのURLが列記されています。\n\nAbemaTVから配信されている`.m3u8`の例\n```\n#EXTM3U\n#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=300000\n240/playlist.m3u8?t=3i87VhR5nuXMsjxJRGBiEYSNPdfggGQtr9LjXNx1fr5Dufac7cEaEKMyo2UAv77B63hAvVewach5eaPjFGK3EU22fcpcFD4RAeNAE7nisDwZguUqvp&mq=720&lanceId=c99528aa-0c3c-4987-ab6c-ce5cd1430223\n#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=900000\n360/playlist.m3u8?t=3i87VhR5nuXMsjxJRGBiEYSNPdfggGQtr9LjXNx1fr5Dufac7cEaEKMyo2UAv77B63hAvVewach5eaPjFGK3EU22fcpcFD4RAeNAE7nisDwZguUqvp&mq=720&lanceId=c99528aa-0c3c-4987-ab6c-ce5cd1430223\n#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=1400000\n480/playlist.m3u8?t=3i87VhR5nuXMsjxJRGBiEYSNPdfggGQtr9LjXNx1fr5Dufac7cEaEKMyo2UAv77B63hAvVewach5eaPjFGK3EU22fcpcFD4RAeNAE7nisDwZguUqvp&mq=720&lanceId=c99528aa-0c3c-4987-ab6c-ce5cd1430223\n#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=2200000\n720/playlist.m3u8?t=3i87VhR5nuXMsjxJRGBiEYSNPdfggGQtr9LjXNx1fr5Dufac7cEaEKMyo2UAv77B63hAvVewach5eaPjFGK3EU22fcpcFD4RAeNAE7nisDwZguUqvp&mq=720&lanceId=c99528aa-0c3c-4987-ab6c-ce5cd1430223\n```\n\nこれはMaster Playlistと呼ばれるデータで、\n回線速度によって異なるビットレートでの配信を行うアダプティブストリーミングのためのファイルです。\n次に示すMedia PlaylistのURLと想定する回線速度が列記されています。\n\nAbemaTVから配信されている`.m3u8`の例\n```\n#EXTM3U\n#EXT-X-VERSION:3\n#EXT-X-TARGETDURATION:6\n#EXT-X-MEDIA-SEQUENCE:4\n#EXT-X-DISCONTINUITY-SEQUENCE:1\n#EXT-X-KEY:METHOD=AES-128,URI=\"abematv://v2/abema-news/abema-news/DUjoiyL1pJGkADZotyiXDn5\",IV=0xaccca4b41de3d9afb029070eb564be40\n#EXTINF:5.005000,\nhttps://abematv.akamaized.net/tsnews/abema-news/h264/720/5BPWe1D8Hu9yCC8HaA3oHS.ts\n#EXTINF:5.005000,\nhttps://abematv.akamaized.net/tsnews/abema-news/h264/720/5SphyMY1TTLvYkFo7B5JuM.ts\n#EXTINF:5.005000,\nhttps://abematv.akamaized.net/tsnews/abema-news/h264/720/2kxyGFo9sH9zUUfKj5USUk.ts\n#EXTINF:5.005000,\nhttps://abematv.akamaized.net/tsnews/abema-news/h264/720/Cz43TVWLgUgqskzvWBBnjA.ts\n```\n\nこれはMedia Playlistと呼ばれるデータで、\n配信されている映像・音声が格納された`.ts`ファイルのURLが列記されています。\n\n### 再生の方法\n\nクライアントは、まず`.m3u8`ファイルを取得します。\nそれがMaster Playlistであれば、回線速度によって適切な`.m3u8`を読みに行きます。\nそれがMedia Playlistであれば、`.ts`ファイルを取得して再生します。\n\nクライアントは、`.m3u8`内のタグと呼ばれるデータ(`#EXT`で始まる行)に従って、`.m3u8`を再読込します。\nライブ配信を行う場合は、クライアントが再読込した際に新しい配信データが追加されていれば良いわけです。\n\n以下に、主要なタグの説明を示します。\n\n#### EXT-X-TARGETDURATION\n\n分割された`.ts`の中で最大の長さに最も近い整数値を指定します。\nクライアントは、およそこの秒数ごとに`.m3u8`を再読込します。\n\nhttps://tools.ietf.org/html/draft-pantos-http-live-streaming-23#section-4.3.3.1\n\n#### EXT-X-MEDIA-SEQUENCE\n\nその`.m3u8`にかかれている一番最初の`.ts`が、放送全体で何番目の`.ts`であるかの値を指定します。\nクライアントが分割された`.ts`を正しく連続再生する上で必要になります。\n\nhttps://tools.ietf.org/html/draft-pantos-http-live-streaming-23#section-4.3.3.2\n\n#### EXTINF\n\n分割された`.ts`１つの秒数。小数で指定できる。\n\nhttps://tools.ietf.org/html/draft-pantos-http-live-streaming-23#section-4.3.2.1\n\n# HLSを再生したい\n\nHLSはブラウザ上で再生できるのが強いです。\nhttps://caniuse.com/#search=HLS\n\nん？？？？？なんか赤いな……\n\n![](hls.png)\n\nFirefoxとChromeが対応してないやんけ！！！！！！！！！\n珍しくEdgeが優秀だ……\n\n悲しいですね。\nでも**Mesia Source Extensions**(MSE)という機能を使うとそれっぽくHLSを再生できるので安心です。\nhttps://caniuse.com/#search=MSE\n\nMSEを使ったHLS再生は、[Video.js](http://videojs.com/)とか[hls.js](https://github.com/video-dev/hls.js/tree/master)とかのライブラリを使うと簡単です。\n\nちなみに、AbemaTVは[THEOplayer](https://www.theoplayer.com/)という有償のプレーヤーを使ってるみたい。\n\n# HLSで生配信\n\nHLSをなんとな～くわかった気になったので、ライブ配信をやってみます。\n\nHLSで生配信をするにはどうすればよいのかというと、つまり\n\n- データをMPEG-2 TSにエンコードする\n- `.m3u8`に`.ts`へのリンクを追加する\n\nを繰り返すだけです。\n\n`.ts`へのを追加していくだけだとドンドン`.m3u8`がでっかくなってしまうので、\n過去の`.ts`へのリンクはある程度時間が立ったら消してしまいましょう。\n`.ts`へのリンクを消したら、`#EXT-X-MEDIA-SEQUENCE`を増やさないとクライアントが困ってしまうので注意です。\n\nとっても単純ですね！\nさて、先述したことをやるだけでライブ配信サーバが書けてしまいます。\n\n今回は、Twitterからタイムラインを取得して、ツイートをいい感じにきりたんに読んでもらい、\nHLSを用いてリアルタイムでその音声データを配信してみます。\n\n音声ファイルを分割してMPEG-2 TSにするのを自分で書くのは流石にしんどいので、\nFFMPEGさんにお願いしました。\nhttps://www.ffmpeg.org/ffmpeg-formats.html#hls-1\n\n## やること\n\n![](system.svg)\n\n### twitter.listen()\n\n- UserStreamでツイート取得\n- kiritan.pyにジョブを投げる\n- encoder.pyのキューに読み上げたWAVファイルを蓄積\n\n### encoder.livestreaming()\n\n- キューにファイルがなければ無音データをプレイリストに追加\n- キューにファイルがあればTSに分割してプレイリストに追加\n- プレイリストの先頭のTSの再生時間分だけ待って、プレイリストから削除\n\n## やりました\n\n方針が定まったら書くだけ……\n\n### コード\n\n全コード\n\nhttps://github.com/kaz/kiritan-server\n\nHLS関係の処理はたったコレだけです！\n```python\n# FFMPEGでファイルをMPEG-TSにエンコード（中身はMP3）\ndef ts(file):\n\tlogging.info(\"Encoding WAV to MPEG-TS\")\n\n\tdata = subprocess.run(\n\t\t[\n\t\t\t\"ffmpeg\",\n\t\t\t\"-i\", file, \"-vn\",\n\t\t\t\"-acodec\", \"libmp3lame\",\n\t\t\t\"-ab\", \"128k\",\n\t\t\t\"-ac\", \"2\",\n\t\t\t\"-ar\", \"44100\",\n\t\t\t\"-f\", \"hls\",\n\t\t\t\"-hls_time\", \"2\",\n\t\t\t\"-hls_list_size\", \"0\",\n\t\t\t\"-start_number\", str(int(time.time() * 1000)),\n\t\t\t\"-hls_segment_filename\", \"static/live%d.ts\",\n\t\t\t\"pipe:1.m3u8\"\n\t\t],\n\t\tstdout=subprocess.PIPE,\n\t\tstderr=subprocess.DEVNULL\n\t)\n\n\t# 出力されたプレイリストをパースして返す\n\tplaylist = data.stdout.decode(\"utf-8\")\n\tplaylist = playlist[playlist.rfind(\"#EXTM3U\"):]\n\n\t# Tuple (再生時間, ファイルパス)\n\treturn re.findall(r\"#EXTINF:([\\d.]+),\\s+(\\S+)\", playlist)\n\n# ライブストリーミングキューに追加\nque = []\ndef enqueue(f):\n\tque.append(f)\n\n# ライブプレイリストを更新\ntsl = []\nseq = 0\ndef __livecasting():\n\tglobal seq\n\n\twhile True:\n\t\ttry:\n\t\t\tif len(que) != 0:\n\t\t\t\t# キューにデータがあればプレイリストに追加\n\t\t\t\ttsl.extend(ts(que.pop(0)))\n\t\t\telse:\n\t\t\t\t# キューが空なら無音ファイルを配信\n\t\t\t\twhile len(tsl) < 3:\n\t\t\t\t\ttsl.append((\"2.04\", \"silent.ts\"))\n\n\t\t\t# TS 1つ分だけ休憩する\n\t\t\ttime.sleep(float(tsl[0][0]))\n\t\t\ttsl.pop(0)\n\t\t\tseq += 1\n\t\texcept:\n\t\t\tlogging.error(traceback.format_exc())\n\n# サーバ起動\ndef livecasting():\n\t# 古い配信データを削除\n\tfor f in glob.glob(\"static/live*\"):\n\t\tos.remove(f)\n\n\tthreading.Thread(target=__livecasting).start()\n\n# ライブプレイリストを生成\ndef playlist():\n\tpl = [\n\t\t\"#EXTM3U\",\n\t\t\"#EXT-X-VERSION:3\",\n\t\t\"#EXT-X-TARGETDURATION:3\",\n\t\t\"#EXT-X-MEDIA-SEQUENCE:%d\" % seq\n\t]\n\n\tfor ts in tsl[:5]:\n\t\tpl.append(\"#EXTINF:%s,\" % ts[0])\n\t\tpl.append(\"#EXT-X-DISCONTINUITY\")\n\t\tpl.append(\"/static/%s\" % ts[1])\n\n\treturn \"\\n\".join(pl)\n```\n\nffmpegを使っているので、別途用意が必要です。\n必要なPythonのライブラリは`pypiwin32`と`flask`と`tweepy`です\n\n```sh\npip install pypiwin32 flask tweepy\n```\n\n## 動作検証\n\n大体のブラウザでhls.jsを介した再生ができました。\n\nネイティブでHLSに対応しているブラウザ(Safari, Edge, iOS Safari, Android Chrome)は、\n`.m3u8`に直接アクセスしても再生できました。\n\nなんかAndroidだとちょっとプツプツしちゃってるかも？？？\n\n## ハマりそうなポイント\n\n- TS1つの長さ、プレイリスト全体の長さ、`#EXT-X-TARGETDURATION`をうまく調整しないと再生されなかったりプツプツなったりする\n\t- このへんどうするのが最適なのかがわからないので今回は試行錯誤した\n- TSが切り替わる（別のメディアから生成したものになる）時に`#EXT-X-DISCONTINUITY`を付けないと再生が止まる\n\t- Appleのソフトウェアはうまくやってくれるけど、その他は上手く行かない\n- TwitterのUserStreamはPCの時計かズレてると認証失敗する\n\n# おしまい\n\nということで、AzureのWindowsServerでWin32APIを使ってVOICEROIDを操作してTwitterのTLを読み上げた音声をHLSでライブ配信できました！\n\nWin32APIとかHLSとか、まだわからないことがたくさんなので、それはおかしいだろ！って思ったら鉞おねがいします＞＜\n\nそれにしても、きりたんはかわいいですね！\n\nおしまい\n","title":"クラウド東北きりたん その3 ～HLSでライブストリーミング～","image":null,"tags":["HLS","VOICEROID","インフラ","ストリーミング","東北きりたん"],"date":"2017-05-25T00:00:00.000Z","updated":"2021-01-07T09:09:45.000Z"},{"type":"article","slug":"17","body":"重い\n\n\n# CPCTF\n\nhttps://ctf-no.pro/\n\nこういうのをやりました。\n\n出題された問題の雰囲気はこういうかんじ（参加してくださった方のwriteupです）\n\nhttp://yuinore.net/2017/04/cpctf-writeup-1/\n\nhttp://yuinore.net/2017/04/cpctf-writeup-2/\n\nサーバ周りは全てボクが担当したんですが、ゴミクソ重くて申し訳なさがXDです。\n\n## 構成\n\n問題が60個とかそれくらいありました。多すぎる。\nで、この問題たちとスコアサーバを全て1台のサーバ(cpu:8Core mem:16GB)で動かしました。\n\n全てのアプリはDockerで環境が分離されています。\n自作のソフトウェア（Dockerのラッパみたいな何か）によって、PaaSみたいな使い心地で問題を更新できる仕組みにしてました。\n\n👆のお陰で、出題ミスが見つかっても更新が非常にスムーズでした。\n最終的に100アカウントくらいが登録されてましたが、サーバも落ちたりせずに概ね順調でした。\n\nが、HTTPでのアクセスがクッッッッッソ遅い問題にぶち当たって険しい感じでした。\nなんか変な感じの挙動で、一度繋がるとそれ以後数10分は快適に繋がるが、\n繋がらない人は永遠につながらない（HTTPレスポンスが帰ってこない）感じ。\n\nで、サーバ全体の負荷も大したことなかったし、ネットワーク帯域も余裕っぽかったので、謎かった。\n\n## 重い理由\n\nサーバが1台で、アプリが沢山乗ってる構成なので、HTTPリクエストを捌いてくれるリバースプロキシとして**OpenResty**さんを使っていて、\nHTTPS化を手っ取り早くやるために[lua-resty-auto-ssl](https://github.com/GUI/lua-resty-auto-ssl)を採用していました。\n\nhttps://github.com/GUI/lua-resty-auto-ssl\n\n[lua-resty-auto-ssl](https://github.com/GUI/lua-resty-auto-ssl)は非常に優秀で、\n**正しく設定すれば**勝手にすべてのページをHTTPS化してくれて便利便利floatです。\n\nでまぁ、結論を言うと重いのはこの人が原因でした。\n\nこの人はOCSP Staplingもやってくれるんですが、コレを正しく動作させるためにはOpenRestyの`resolver`設定をしてあげないとダメです。\nどうダメかというと、遅くなります。おそらくDNSの問い合わせができずにそこでワーカーが止まってしまい永遠にレスポンスが帰ってこないのかな？\n\nエラーログにはOCSPが失敗したよ！っていうログがいっぱい出ていなので、コレが問題なのは間違いないんですが詳しい原因はコレ以上分からずです。\n一旦繋がると以後は素早く繋がるのは多分、一度OCSPで証明書の正当性が確認されるとしばらくは確認しないから……？\nでもOCSP Staplingってサーバ側が能動的に送ってるものな気がするし違うのでしょうか……\n\nそれと、[lua-resty-auto-ssl](https://github.com/GUI/lua-resty-auto-ssl)が内部で使ってるLetsencryptクライアントの\n[dehydrated](https://github.com/lukas2511/dehydrated)は、デフォルトだとRSA **4096bit**の証明書を作成します。\n4096bitは結構遅いです。適当に`ab`で計測したら4096bitは2048bitを比較してリクエスト完了まで10倍くらいの時間がかかってました。\n\n## Dockerの内部DNS\n\nさっきのOpenRestyはDockerコンテナ内で動かしてたんですが、\nDocker内部だとデフォルトゲートウェイがDockerネットワーク内でのホストのアドレスなので、\nDNSのについてもこの人がやってくれてるんだろうな〜〜って勝手に思って勝手にそう指定してたんですが、これが間違いでした。\n\nDockerネットワーク内でのDNSサーバは、`127.0.0.11`が正しいそうです。\nというか、resolve.confを見たらちゃんと書いてあったわ……\n\n## おわり\n\nわからないことが多いです。\n誰か鉞投げて欲しい。\n","title":"新入生向けCTF体験会のスコアサーバが重かった","image":null,"tags":["CTF","DNS","Docker","インフラ","ネットワーク","日記"],"date":"2017-05-17T00:00:00.000Z","updated":"2021-01-07T09:09:45.000Z"},{"type":"article","slug":"16","body":"GitLabのマネをしました。\n\n作業していたら突然サーバが爆発しました。怖いです。\n\nええと、何があったのかというと、ミスって**Webアプリのデータの大部分を吹き飛ばして**しまいました。\n個人鯖じゃなくて、大学サークルの部内システムが全部乗っかってるサーバなのでやばばばいです。\n\n# 原因\n\n![](1.png)\n\nこれです。Win機ではいつもrloginというsshクライアントを使って作業しているんですが、\nこのクライアントには**コマンドを複数のサーバに同時送信する機能**が搭載されています。\n\nボクはこの事を知らなかったんですが、クリックミスでいつの間にか有効化してしまっていたんですね。\n\nで、このときボクは来る新入生歓迎CTF大会の鯖を構築していました。\n設定ファイルをコピーするために、**メインサーバにもSSHログイン**した状態でした。\n鯖構築序盤なので、いろいろ試行錯誤しつつ`rm -rf`なんかも連打してたんですね……\n\n本鯖にも`rm -rf`が飛んでることなど露知らず……！\nメインサーバ落ちてるよ～って連絡を受けて確認したらすっかりCTFサーバと化したメインアプリサーバが……。\n\n# 被害\n\nバックアップ等から復元して、ほとんどのアプリは事なきを得たのですが、部内SNS(内製)だけが致命的な打撃を被りました。\n\n一番被害が大きかったのがアップロードされたファイル群です。これらが一時全て削除されてしまいました。\nこれらは、非常に大容量なので別の場所にバックアップするのが億劫になって放ったらかしになっていたのでした……\n\nまた、重要な設定ファイルが損失してこちらの復旧も非常に大変でした。\n\n# 対応\n\n4/16夜から4/17早朝にかけてのお話です\n\n## 19:40 CTF鯖が起動\n\nサーバ構築を始めました。この時点でコマンドブロードキャストが有効になっています。\n（そういえばカーソルが変な形になってて妙だな……と思っていたのでした。。。）\n\n## 20:00 メインサーバに致命的なコマンドが飛ぶ\n\nちょっとやり直そうと思って`rm -rf`で色んな所消しました。\nメインサーバの大事なトコロにも直撃してます。\n\n## 20:10 メインサーバの死が報告され始める\n\nhttps://twitter.com/NorthWest_Bread/status/853568096845430784\n\nこの時点では何が起きたのか分かってません。\n\n## 20:30 全てを悟る\n\nさっきまで弄っていたCTF鯖とメイン鯖の`.bash_history`が一致しているのを見て何が起きたのか気が付きました。\n（なるほどね）（時既に遅し）（やばい）\n\n## 20:40 メインサーバを止める\n\n復元することを考えて、ディスクに上から書き込まれてしまわないようにサーバを止めました。\n`ddrescue`でディスクをダンプしておきました。\n\n## 20:50 いろいろ試してみる\n\nextundeleteとかを試してみますが、歯が立たず。\n\n## 21:00 データが無事なアプリを別サーバに移す\n\nとりあえず、ディスクをダンプしたデータから無事なアプリを復旧する作業に移る。\n新しくサーバを立て直します。\n\n## 22:00 gitホスティングサービスが復旧\n\nメンテナンス用コードなんかも入っているので真っ先に復旧させました。\n\n## 22:30 ブログが復旧\n\nブログにアップロードされたデータは全てオブジェクトストレージに逃がしていたので、無傷でした。\n\n## 22:50 wikiが復旧\n\nwikiも同じく、データの大部分がオブジェクトストレージにあるため無事。\n\n## 23:00 photorec/foremostでファイルを救出する作戦に出る\n\nextundeleteが不発だったので、👆を使ってファイルを抜き出します。\nただし、ファイル名がわからなくなってしまうのでDBとの整合性を取る作業が非常に大変になりそうだなぁとか思ってました。\nそもそも、アップロードされたファイルの情報は元のファイル名とサイズとタイムスタンプ、MIMEタイプしかありません。\nこのなかで使えるのはMIMEタイプとファイルサイズのみです。\n\n## 00:30 DBマイグレーション時の対応表を発見\n\n昔にDBスキーマを変更したときのバックアップデータを見つけました。\nこのデータを使うことで、約30%のデータが完全復旧できました。\n\n## 02:30 復元スクリプトが完成\n\nphotorec/foremostを併用してデータ復元作業を行います。\n\n## 03:10 復元完了\n\nおよそ 75% データが復元できました。\n13% のデータは、破損していて元に戻せませんでした。\n残りの 12% は、データはおそらく拾い出せているが、同じサイズやMIMEタイプのデータが複数存在するため、元のファイルがどれかわからない状態です。\nこちらについては、人力で対応表を作ればもとに戻せる可能性はあります。\n\n## 03:20 部内SNS復旧作業\n\nこちらもなかなか難航しました。\nなくなってしまったファイルの扱いについて、アプリの改修を行う必要がありました。\n\n部内のシステムは全て独自方式SSOで接続されており、ここでは公開鍵暗号を使って認証を行っています。\nここで用いていた権威サーバの秘密鍵が失われたので、アプリ側に配布している公開鍵を全て更新する作業が必要になりました。\n\nまた、APNsやGCMの通知に使うキーも失われたので再発行を行いました。\n\n## 05:00 再開\n\n全て元に戻りました。\n25%くらいのデータが欠けてしまいましたが……。\n\n# まとめ\n\n## 対策\n\n- バックアップは取る\n- むやみにrootにならない\n\t- いちいちsudoうつの面倒だったんだもん＞＜\n\n## extundelete\n\n無能\n（ext4だったからね）\n\n## photorecとforemost\n\nphotorecで戻せたけどforemostで戻らないファイルとか、その逆もある。\n両方合わせて使うと良いかもしれない。あとCTFer御用達の`binwalk`でも似たようなことができるのかな？\n\n## 感想\n\n同時送信怖すぎる……\nというかもっとわかりやすく表示してくれ\n\nお陰でCTFの準備が一ミリも進んでなくてマズい\nというかリアルにフォレンジックすることになるとは思わんかった\n\n教訓にします\n\nゴメンナサイm(_ _)m\n\n![](2.jpg)\n","title":"鯖が爆発した","image":null,"tags":["インフラ","日記"],"date":"2017-04-17T00:00:00.000Z","updated":"2021-01-07T09:09:45.000Z"},{"type":"external","url":"https://trap.jp/post/39/","publisher":"東京工業大学デジタル創作同好会traP","title":"ConoHaでArchLinuxを動かすまで","tags":["traP","インフラ","ConoHa"],"date":"2016-02-25T00:00:00.000Z"}]},"__N_SSG":true}